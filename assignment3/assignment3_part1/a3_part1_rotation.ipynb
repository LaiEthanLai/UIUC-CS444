{"cells":[{"cell_type":"markdown","metadata":{"id":"Um5DJvBwb6xT"},"source":["#Data Setup\n","\n","The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n","\n","Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oHkeNUOKiFbP"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import random\n","import os\n","\n","def rotate_img(img, rot):\n","    if rot == 0: # 0 degrees rotation\n","        return img\n","    elif rot == 1:\n","        return transforms.functional.rotate(img, 90)\n","    elif rot == 2:\n","        return transforms.functional.rotate(img, 180)\n","    elif rot == 3:\n","        return transforms.functional.rotate(img, 270)\n","    else:\n","        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n","\n","\n","class CIFAR10Rotation(torchvision.datasets.CIFAR10):\n","\n","    def __init__(self, root, train, download, transform) -> None:\n","        super().__init__(root=root, train=train, download=download, transform=transform)\n","    \n","    def __len__(self):\n","        return len(self.data)\n","        \n","    def __getitem__(self, index: int):\n","        image, cls_label = super().__getitem__(index)\n","\n","        # randomly select image rotation\n","        rotation_label = random.choice([0, 1, 2, 3])\n","        image_rotated = rotate_img(image, rotation_label)\n","\n","        rotation_label = torch.tensor(rotation_label).long()\n","        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Preparing ImageNette dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections.abc import Callable\n","from typing import Any, Optional\n","from PIL import Image\n","# imagenette dataset, download here: https://github.com/fastai/imagenette \n","lbl_dict = dict(\n","    n01440764='tench',\n","    n02102040='English springer',\n","    n02979186='cassette player',\n","    n03000684='chain saw',\n","    n03028079='church',\n","    n03394916='French horn',\n","    n03417042='garbage truck',\n","    n03425413='gas pump',\n","    n03445777='golf ball',\n","    n03888257='parachute'\n",") # from fastai document\n","\n","# mean, var of each channel are computed by dataset_stat.py (single channel pics are pruned)\n","transform_train = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4601, 0.4564, 0.4305), (0.0818, 0.0795, 0.0930)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4601, 0.4564, 0.4305), (0.0818, 0.0795, 0.0930)),\n","])\n","\n","batch_size = 64\n","def pil_loader(path: str) -> Image.Image:\n","    with open(path, \"rb\") as f:\n","        img = Image.open(f)\n","        return img.convert(\"RGB\")\n","    \n","class rotate_Image_folder(torchvision.datasets.ImageFolder):\n","    def __init__(self, root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = pil_loader, is_valid_file: Optional[Callable[[str], bool]] = None):\n","        super().__init__(root, transform, target_transform, loader, is_valid_file)\n","\n","    def __len__(self) -> int:\n","        return len(self.samples)\n","    \n","    def __getitem__(self, index: int):\n","        image, cls_label = super().__getitem__(index)\n","        \n","\n","        # randomly select image rotation\n","        rotation_label = random.choice([0, 1, 2, 3])\n","        image_rotated = rotate_img(image, rotation_label)\n","\n","        rotation_label = torch.tensor(rotation_label).long()\n","        return image, image_rotated, rotation_label, torch.tensor(cls_label).long()\n","        \n","\n","trainset = rotate_Image_folder(root='data/imagenette2/train', transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=8)\n","\n","testset = rotate_Image_folder(root='data/imagenette2/val', transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=8)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Preparing CIFAR10 dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCBSpNWpb8uw"},"outputs":[],"source":["transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","batch_size = 128\n","\n","trainset = CIFAR10Rotation(root='./data', train=True,\n","                                        download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=8)\n","\n","testset = CIFAR10Rotation(root='./data', train=False,\n","                                       download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=8)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dOCWMyGhVOJB"},"source":["Show some example images and rotated images with labels:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9wN4BJWVMzB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","rot_classes = ('0', '90', '180', '270')\n","\n","\n","def imshow(img):\n","    # unnormalize\n","    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)\n","    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","dataiter = iter(trainloader)\n","images, rot_images, rot_labels, labels = next(dataiter)\n","\n","# print images and rotated images\n","img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n","print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n","img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n","print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"]},{"cell_type":"markdown","metadata":{"id":"unCucbHexG4W"},"source":["#Evaluation code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pptQRpqK0rOl"},"outputs":[],"source":["import time\n","\n","def run_test(net, testloader, criterion, task):\n","    correct = 0\n","    total = 0\n","    avg_test_loss = 0.0\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for images, images_rotated, labels, cls_labels in testloader:\n","            if task == 'rotation':\n","              images, labels = images_rotated.to(device), labels.to(device)\n","            elif task == 'classification':\n","              images, labels = images.to(device), cls_labels.to(device)\n","            # TODO: Calculate outputs by running images through the network\n","            # The class with the highest energy is what we choose as prediction\n","            \n","            outputs = net(images)\n","            predicted = outputs.argmax(axis=1)\n","            # loss\n","            \n","            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n","            total += outputs.shape[0]\n","            correct += (predicted == labels).sum().item()\n","            \n","    print('TESTING:')\n","    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n","    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')\n","  \n","    return 100 * correct / total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hf698c16A9k5"},"outputs":[],"source":["def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n","    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"]},{"cell_type":"markdown","metadata":{"id":"3lYdnb1Wsta_"},"source":["#Train a ResNet18 on the rotation task\n","\n","In this section, we will train a ResNet18 model on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knAiwdURvBHk"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# device = 'mps' if torch.backends.mps.is_available() and torch.backends.mps.is_built() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"235MEIUgsv65"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18, resnet50, resnet101, resnext101_32x8d\n","import torch._dynamo\n","\n","# torch.set_float32_matmul_precision('high')\n","\n","# torch._dynamo.reset()\n","net = resnet101(num_classes=4)\n","net = net.to(device)\n","# net = torch.compile(net, mode=\"reduce-overhead\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vuhiw0ZoszAd"},"outputs":[],"source":["import torch.optim as optim\n","\n","lr = 1e-3\n","restart_epoch = 50\n","# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(params=net.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-3)\n","scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=restart_epoch, T_mult=2, eta_min=1e-8, last_epoch=- 1, verbose=True)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WleH-YBgs0rq"},"outputs":[],"source":["# Both the self-supervised rotation task and supervised CIFAR10 classification are\n","# trained with the CrossEntropyLoss, so we can use the training loop code.\n","\n","def train(net, criterion, optimizer, scaler, num_epochs, decay_epochs, init_lr, task, scheduler=None, weight_best=None, weight_interval=None, restart_epoch=None):\n","\n","    best_acc = -10\n","    best_epoch = -10\n","\n","    for epoch in range(num_epochs):  # loop over the dataset multiple times\n","\n","        running_loss = 0.0\n","        running_correct = 0.0\n","        running_total = 0.0\n","        start_time = time.time()\n","\n","        net.train()\n","\n","        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n","            \n","            if scheduler is None:\n","                adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n","\n","            if task == 'rotation':\n","                images, labels = imgs_rotated.to(device), rotation_label.to(device)\n","            elif task == 'classification':\n","                images, labels = imgs.to(device), cls_label.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            with torch.autocast(device_type='cuda', dtype=torch.float16):\n","                outputs = net(images)\n","                loss = criterion(outputs, labels)\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            \n","\n","            # print(outputs.shape)\n","            predicted = outputs.argmax(axis=1)\n","\n","            # print statistics\n","            print_freq = 50\n","            running_loss += loss.item()\n","\n","            # calc acc\n","            running_total += labels.size(0)\n","            running_correct += (predicted == labels).sum().item()\n","\n","            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n","                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n","                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n","                start_time = time.time()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        if restart_epoch is not None and weight_interval is not None:\n","            if (epoch+1) % restart_epoch == 0:\n","                torch.save(\n","                    net.state_dict(), f'{weight_interval}_epoch{epoch+1}.pt'\n","                )    \n","        \n","        net.eval()\n","        test_acc = run_test(net, testloader, criterion, task)\n","        if test_acc > best_acc:\n","            best_acc = test_acc\n","            best_epoch = epoch + 1\n","            if weight_best is not None:\n","                torch.save(\n","                    net.state_dict(), weight_best\n","                )\n","\n","    print('Finished Training')\n","    print(f'Best Acc: {best_acc} at epoch: {best_epoch}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pretrained_weight_interval = 'ssl_pretrained_resnet101_sfd_cosine_v5'\n","pretrained_weight_best = 'ssl_pretrained_resnet101_sfd_cosine_v5_best.pt'\n","train(net, criterion, optimizer, scaler, num_epochs=1000, decay_epochs=50, init_lr=0.001, task='rotation', scheduler=scheduler, weight_best=pretrained_weight_best, weight_interval=pretrained_weight_interval, restart_epoch=100)\n","\n","# resnet18 78.74%\n","# resnet101 (SGD + CosineAnnealing) 90.76 %\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from glob import glob\n","import time\n","\n","correct = 0\n","total = 0\n","ppp = 0\n","\n","with torch.no_grad():\n","    for images, images_rotated, labels, cls_labels in testloader:\n","        \n","        images, labels = images_rotated.to(device), labels.to(device)\n","        predictions = {}\n","        for i in range(images.shape[0]):\n","            predictions[i] = []\n","\n","        for weight in ['ssl_pretrained_resnet101_sfd_cosine_v5_best.pt', 'ssl_pretrained_resnet101_sfd_cosine_v5_epoch700.pt', 'ssl_pretrained_resnet101_sfd_cosine_v4_best.pt']: # choose trained NN candidates you desire\n","            \n","            net.load_state_dict(torch.load(weight))\n","            outputs = net(images)\n","            pred = outputs.argmax(axis=1)\n","            \n","            for idx, i in enumerate(pred):\n","                predictions[idx].append(int(i))\n","        \n","        predicted = torch.ones(images.shape[0])\n","        for i in range(images.shape[0]):\n","            predicted[i] = max(set(predictions[i]), key=predictions[i].count)\n","            \n","        total += outputs.shape[0]\n","        correct += (predicted == labels.cpu()).sum().item()\n","            \n","    print('TESTING:')\n","    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n","# resnet101: 90.69%\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2u4AsfAKtaQS"},"outputs":[],"source":["train(net, criterion, optimizer, scaler, num_epochs=190, decay_epochs=30, init_lr=0.01, task='rotation')\n","\n","pretrained_weight = 'ssl_pretrained_imagenette.pt'\n","torch.save(\n","    net.state_dict(), pretrained_weight\n",")\n","# 65.09% imagenette \n"]},{"cell_type":"markdown","metadata":{"id":"PLLMRTS9rTnk"},"source":["##Fine-tuning on the pre-trained model\n","\n","In this section, we will load the pre-trained ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4nX4ExlrymI"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18, ResNet18_Weights\n","from gc import collect\n","\n","del net\n","collect()\n","net = resnet101(num_classes=4).to(device)\n","net.load_state_dict(torch.load('ssl_pretrained_resnet101_sfd_cosine_v5_best.pt'))\n","net.fc = nn.Linear(2048, 10).to(device)\n","# net = torch.compile(net, mode=\"reduce-overhead\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kD44g-TxwYdU"},"outputs":[],"source":["for name, param in net.named_parameters():\n","    if not 'fc' in name and not 'layer4' in name: \n","        param.requires_grad = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9T5DX0efr4fh"},"outputs":[],"source":["# Print all the trainable parameters\n","params_to_update = net.parameters()\n","print(\"Params to learn:\")\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb032dG700ph"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(params=net.parameters(), lr=1e-3)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vLSwOo6sBjl"},"outputs":[],"source":["train(net, criterion, optimizer, scaler, num_epochs=20, decay_epochs=10, init_lr=0.001, task='classification')\n","# 82.75% (if freeze layer4 and fc) (super weird...) -> for next section, fc and layer4 should have higher lr, otherwise lower\n","# resnet 18: 61.2"]},{"cell_type":"markdown","metadata":{"id":"ghPNhcJBrcNj"},"source":["## Fine-tuning on the randomly initialized model\n","In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RfXAh9vxXRB"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","del net\n","collect()\n","net = resnet101(num_classes=10).to(device)\n","# net = torch.compile(net, mode=\"reduce-overhead\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpx-SYAizt4p"},"outputs":[],"source":["for name, param in net.named_parameters():\n","    if not 'fc' in name and not 'layer4' in name: \n","        param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUFWizbHxgm2"},"outputs":[],"source":["# Print all the trainable parameters\n","params_to_update = net.parameters()\n","print(\"Params to learn:\")\n","params_to_update = []\n","for name,param in net.named_parameters():\n","    if param.requires_grad == True:\n","        params_to_update.append(param)\n","        print(\"\\t\",name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BxFrGj091AN_"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(params=net.parameters(), lr=1e-3)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzRVy0MZxpoL"},"outputs":[],"source":["train(net, criterion, optimizer, scaler, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')\n","# 83.21% (if freeze layer4 and fc) (super weird...) \n","# resnet 18: 46.23"]},{"cell_type":"markdown","metadata":{"id":"WcN54tcNN15U"},"source":["##Supervised training on the pre-trained model\n","In this section, we will load the pre-trained ResNet18 model and re-train the whole model on the classification task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xR9h_S1N6Xi"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18\n","\n","# net = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n","net = resnet101(num_classes=4).to(device)\n","net.load_state_dict(torch.load('ssl_pretrained_resnet101_sfd_cosine_v5_best.pt'))\n","net.fc = nn.Linear(2048, 10).to(device)\n","# net = torch.compile(net, mode=\"reduce-overhead\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGozc2cM0ADw"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(params=net.parameters(), lr=1e-3, weight_decay=1e-3)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGWW7gzCz_Bu"},"outputs":[],"source":["train(net, criterion, optimizer, scaler, num_epochs=100, decay_epochs=40, init_lr=0.0005, task='classification')\n","# resnet18 84.2%\n","# resnet101 90.32%"]},{"cell_type":"markdown","metadata":{"id":"xjVTp9jhefTi"},"source":["##Supervised training on the randomly initialized model\n","In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEjy8TBieeLK"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchvision.models import resnet18, ResNet18_Weights\n","\n","# TODO: Randomly initialize a ResNet18 model\n","del net\n","collect()\n","net = resnet101().to(device)\n","# net = resnet18(weights=ResNet18_Weights.DEFAULT).to(device)\n","# net.fc = nn.Linear(512, 10).to(device)\n","# net = torch.compile(net, mode=\"reduce-overhead\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEY90pK_0ZAm"},"outputs":[],"source":["# TODO: Define criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(params=net.parameters(), lr=1e-3, weight_decay=1e-3)\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMDwelhY0auO"},"outputs":[],"source":["train(net, criterion, optimizer, scaler, num_epochs=210, decay_epochs=40, init_lr=0.01, task='classification')\n","# resnet18 82.45%\n","# resnet101 87.55"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1qQ3NEaCUln7yDSksrEOnDwrt3u9dYNr4","timestamp":1677623843954}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.16 ('t_v2')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"6cd8fbe6147f303dfbd569aceacf292c1eb4b0e76338b28c6bab9204602e3a58"}}},"nbformat":4,"nbformat_minor":0}
