{"cells":[{"cell_type":"markdown","metadata":{"id":"O452YP5gcoTh"},"source":["# Assignment 2\n","\n","In this assignment you will create a coordinate-based multilayer perceptron in numpy from scratch. For each input image coordinate $(x,y)$, the model predicts the associated color $(r,g,b)$.\n","\n","![Network diagram](https://user-images.githubusercontent.com/3310961/85066930-ad444580-b164-11ea-9cc0-17494679e71f.png)\n","\n","You will then compare the following input feature mappings $\\gamma (\\mathbf{v})$.\n","\n","- No mapping: $\\gamma(\\mathbf{v})= \\mathbf{v}$. \n","\n","- Basic mapping: $\\gamma(\\mathbf{v})=\\left[ \\cos(2 \\pi \\mathbf{v}),\\sin(2 \\pi \\mathbf{v}) \\right]^\\mathrm{T}$. \n","\n","- Gaussian Fourier feature mapping: $\\gamma(\\mathbf{v})= \\left[ \\cos(2 \\pi \\mathbf B \\mathbf{v}), \\sin(2 \\pi \\mathbf B \\mathbf{v}) \\right]^\\mathrm{T}$, \n","where each entry in $\\mathbf B \\in \\mathbb R^{m \\times d}$ is sampled from $\\mathcal N(0,\\sigma^2)$.\n","\n","Some notes to help you with that:\n","\n","- You will implement the mappings in the helper functions `get_B_dict` and `input_mapping`. \n","- The basic mapping can be considered a case where $\\mathbf B \\in \\mathbb R^{2 \\times 2}$ is the indentity matrix. \n","- For this assignment, $d$ is 2 because the input coordinates in two dimensions. \n","- You can experiment with $m$ and $\\sigma$ values e.g. $m=256$ and $\\sigma \\in \\{1, 10, 100\\}$.\n","\n","Source: https://bmild.github.io/fourfeat/ \n","This assignment is inspired by and built off of the authors' demo. "]},{"cell_type":"markdown","metadata":{"id":"g1PrabcYcszP"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"EfPlwYF07wB_"},"source":["### Imports"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"5CKY4Fdna2Y-"},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["import matplotlib.pyplot as plt\n","import os, imageio\n","import cv2\n","import numpy as np\n","\n","# imports /content/assignment2/models/neural_net.py if you mounted correctly \n","from models.neural_net import NeuralNetwork\n","\n","# makes sure your NeuralNetwork updates as you make changes to the .py file\n","%load_ext autoreload\n","%autoreload 2\n","\n","# sets default size of plots\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0)  "]},{"cell_type":"markdown","metadata":{"id":"MhqQzPGU7dls"},"source":["## Helper Functions"]},{"cell_type":"markdown","metadata":{"id":"jWYSuPu2mP8x"},"source":["### Experiment Runner (Fill in TODOs)"]},{"cell_type":"code","execution_count":122,"metadata":{"id":"tSdrQ0QR92tt"},"outputs":[],"source":["def NN_experiment(X_train, y_train, X_test, y_test, input_size, num_layers,\\\n","                  hidden_size, hidden_sizes, output_size, epochs,\\\n","                  learning_rate, opt, batch_size, weight_decay, beta1):\n","  \n","    # Initialize a new neural network model\n","    net = NeuralNetwork(input_size, hidden_sizes, output_size, num_layers, opt, batch_size=batch_size)\n","\n","    # Variables to store performance for each epoch\n","    train_loss = np.zeros(epochs)\n","    train_psnr = np.zeros(epochs)\n","    test_psnr = np.zeros(epochs)\n","    test_loss = np.zeros(epochs)\n","    predicted_images = np.zeros((epochs, y_test.shape[0], y_test.shape[1]))\n","\n","    BATCH_SIZE = batch_size\n","\n","    cur_lr = learning_rate\n","    step = 0\n","    for epoch in (range(epochs)):\n","        \n","        \n","        # Shuffle the dataset\n","        index = np.random.permutation(X_train.shape[0])\n","        X_train_shuffled = X_train[index]\n","        y_train_shuffled = y_train[index]\n","\n","        num_step = X_train.shape[0] // BATCH_SIZE \n","\n","        loss_ = 0.0\n","        psnr_ = 0.0\n","        for i in range(num_step):\n","            step += 1\n","            # Training\n","            # Run the forward pass of the model to get a prediction and record the psnr\n","            output = net.forward(X_train_shuffled[i*BATCH_SIZE : (i+1)*BATCH_SIZE])\n","            psnr_ += psnr(y_train_shuffled[i*BATCH_SIZE : (i+1)*BATCH_SIZE], output)\n","\n","            # Run the backward pass of the model to compute the loss, record the loss, and update the weights\n","            loss_ += net.backward(y_train_shuffled[i*BATCH_SIZE : (i+1)*BATCH_SIZE])\n","            # print('loss:', loss_)\n","            net.update(t=step, lr=cur_lr, b1=beta1, weight_decay=weight_decay)\n","\n","        train_loss[epoch] = loss_ / num_step\n","        train_psnr[epoch] = psnr_ / num_step\n","\n","        if (epoch+1)%50 == 0 and epoch > 1000 and opt == 'SGD':\n","            cur_lr *= 0.5\n","        elif (epoch+1)%200 == 0 and epoch > 600 and opt == 'Adam':\n","            cur_lr *= 0.8\n","\n","        \n","        # Testing\n","        # No need to run the backward pass here, just run the forward pass to compute and record the psnr\n","        predicted_images[epoch] = net.forward(X_test)\n","        test_psnr[epoch] = psnr(y_test, predicted_images[epoch])\n","        test_loss[epoch] = net.mse(y_test, predicted_images[epoch])\n","\n","        # print('testing psnr of epoch {}: {}'.format((epoch+1), psnr(y_test[i*BATCH_SIZE : (i+1)*BATCH_SIZE], output)))\n","        \n","    return net, train_psnr, test_psnr, train_loss, predicted_images, test_loss"]},{"cell_type":"markdown","metadata":{"id":"F_D1y-kJ7eMk"},"source":["### Image Data and Feature Mappings (Fill in TODOs)"]},{"cell_type":"code","execution_count":123,"metadata":{"id":"xcvnzOICobu3"},"outputs":[],"source":["# Data loader - already done for you\n","def get_image(size=512, \\\n","              image_url='https://bmild.github.io/fourfeat/img/lion_orig.png'):\n","\n","  # Download image, take a square crop from the center  \n","  img = imageio.imread(image_url)[..., :3] / 255.\n","  c = [img.shape[0]//2, img.shape[1]//2]\n","  r = 256\n","  img = img[c[0]-r:c[0]+r, c[1]-r:c[1]+r]\n","\n","  if size != 512:\n","    img = cv2.resize(img, (size, size))\n","\n","  plt.imshow(img)\n","  plt.show()\n","\n","  # Create input pixel coordinates in the unit square\n","  coords = np.linspace(0, 1, img.shape[0], endpoint=False)\n","  x_test = np.stack(np.meshgrid(coords, coords), -1)\n","  test_data = [x_test, img]\n","  train_data = [x_test[::2, ::2], img[::2, ::2]]\n","  \n","  return train_data, test_data"]},{"cell_type":"code","execution_count":124,"metadata":{"id":"6YksepPb8Yyw"},"outputs":[],"source":["# Create the mappings dictionary of matrix B -  you will implement this\n","def get_B_dict(var_list):\n","  B_dict = {}\n","  B_dict['none'] = None\n","  \n","  # add B matrix for basic, gauss_1.0, gauss_10.0, gauss_100.0\n","  B_dict['basic'] = np.eye(2)\n","  for i in var_list:\n","    B_dict['gauss_{}'.format(i)] = np.random.normal(0, i, (256, 2))\n","\n","  return B_dict"]},{"cell_type":"code","execution_count":125,"metadata":{"id":"B_9mubvp8aY1"},"outputs":[],"source":["# Given tensor x of input coordinates, map it using B - you will implement\n","def input_mapping(x, B):\n","  if B is None:\n","    # \"none\" mapping - just returns the original input coordinates\n","    return x\n","  else:\n","    # \"basic\" mapping and \"gauss_X\" mappings project input features using B\n","    proj = 2 * np.pi * np.matmul(x, B.T)\n","    return np.concatenate([np.sin(proj), np.cos(proj)], axis=-1)"]},{"cell_type":"code","execution_count":126,"metadata":{"id":"UBGd4KfYjJ14"},"outputs":[],"source":["# Apply the input feature mapping to the train and test data - already done for you\n","def get_input_features(B_dict, mapping):\n","  # mapping is the key to the B_dict, which has the value of B\n","  # B is then used with the function `input_mapping` to map x  \n","  \n","  y_train = train_data[1].reshape(-1, output_size)\n","  y_test = test_data[1].reshape(-1, output_size)\n","  X_train = input_mapping(train_data[0].reshape(-1, 2), B_dict[mapping])\n","  X_test = input_mapping(test_data[0].reshape(-1, 2), B_dict[mapping])\n","  return X_train, y_train, X_test, y_test\n"]},{"cell_type":"markdown","metadata":{"id":"-XZiVy05or2V"},"source":["### MSE Loss and PSNR Error (Fill in TODOs)"]},{"cell_type":"code","execution_count":127,"metadata":{"id":"CdJbDPL9iOer"},"outputs":[],"source":["def mse(y, p):\n","  # make sure it is consistent with your implementation in neural_net.py\n","  return np.mean((y-p)**2)\n","\n","def psnr(y, p):\n","  return -10 * np.log10(mse(y, p))"]},{"cell_type":"markdown","metadata":{"id":"yeXQlG8T7ZzD"},"source":["### Plotting"]},{"cell_type":"code","execution_count":128,"metadata":{"id":"3SniGS2aA_Ic"},"outputs":[],"source":["def plot_training_curves(train_loss, test_loss, train_psnr, test_psnr):\n","\n","  # plot the training loss\n","  plt.subplot(2, 1, 1)\n","  plt.plot(train_loss, label='train')\n","  plt.plot(test_loss, label='test')\n","  plt.title('MSE history')\n","  plt.xlabel('Iteration')\n","  plt.ylabel('MSE Loss')\n","  plt.legend()\n","\n","  # plot the training and testing psnr\n","  plt.subplot(2, 1, 2)\n","  plt.plot(train_psnr, label='train')\n","  plt.plot(test_psnr, label='test')\n","  plt.title('PSNR history')\n","  plt.xlabel('Iteration')\n","  plt.ylabel('PSNR')\n","  plt.legend()\n","\n","  plt.tight_layout()\n","  plt.show()"]},{"cell_type":"code","execution_count":129,"metadata":{"id":"GXY0gCikFAup"},"outputs":[],"source":["def plot_reconstruction(p, y_test):\n","  p_im = p.reshape(size,size,3)\n","  y_im = y_test.reshape(size,size,3)\n","\n","  plt.figure(figsize=(12,6))\n","\n","  # plot the reconstruction of the image\n","  plt.subplot(1,2,1), plt.imshow(p_im), plt.title(\"reconstruction\")\n","\n","  # plot the ground truth image\n","  plt.subplot(1,2,2), plt.imshow(y_im), plt.title(\"ground truth\")\n","\n","  print(\"Final Test MSE\", mse(y_test, p))\n","  print(\"Final Test psnr\",psnr(y_test, p))"]},{"cell_type":"code","execution_count":130,"metadata":{"id":"VcYZUf9RE-2a"},"outputs":[],"source":["def plot_reconstruction_progress(predicted_images, y_test, N=8):\n","  total = len(predicted_images)\n","  step = total // N\n","  plt.figure(figsize=(24, 4))\n","\n","  # plot the progress of reconstructions\n","  for i, j in enumerate(range(0,total, step)):\n","      plt.subplot(1, N, i+1)\n","      plt.imshow(predicted_images[j].reshape(size,size,3))\n","      plt.axis(\"off\")\n","      plt.title(f\"iter {j}\")\n","\n","  # plot ground truth image\n","  plt.subplot(1, N+1, N+1)\n","  plt.imshow(y_test.reshape(size,size,3))\n","  plt.title('GT')\n","  plt.axis(\"off\")\n","  plt.show()"]},{"cell_type":"code","execution_count":131,"metadata":{"id":"C3r5qSy3E9jy"},"outputs":[],"source":["def plot_feature_mapping_comparison(outputs, gt):\n","  # plot reconstruction images for each mapping\n","  plt.figure(figsize=(24, 4))\n","  N = len(outputs)\n","  for i, k in enumerate(outputs):\n","      plt.subplot(1, N+1, i+1)\n","      plt.imshow(outputs[k]['pred_imgs'][-1].reshape(size, size, -1))\n","      plt.title(k)\n","  plt.subplot(1, N+1, N+1)\n","  plt.imshow(gt)\n","  plt.title('GT')\n","  plt.show()\n","\n","  # plot train/test error curves for each mapping\n","  iters = len(outputs[k]['train_psnrs'])\n","  plt.figure(figsize=(16, 6))\n","  plt.subplot(121)\n","  for i, k in enumerate(outputs):\n","      plt.plot(range(iters), outputs[k]['train_psnrs'], label=k)\n","  plt.title('Train error')\n","  plt.ylabel('PSNR')\n","  plt.xlabel('Training iter')\n","  plt.legend()\n","  plt.subplot(122)\n","  for i, k in enumerate(outputs):\n","      plt.plot(range(iters), outputs[k]['test_psnrs'], label=k)\n","  plt.title('Test error')\n","  plt.ylabel('PSNR')\n","  plt.xlabel('Training iter')\n","  plt.legend()\n","  plt.show()"]},{"cell_type":"code","execution_count":132,"metadata":{"id":"k9c5MGtCE8Wf"},"outputs":[],"source":["# Save out video\n","def create_and_visualize_video(outputs, size=size, epochs=epochs, filename='training_convergence.mp4'):\n","  all_preds = np.concatenate([outputs[n]['pred_imgs'].reshape(epochs,size,size,3)[::25] for n in outputs], axis=-2)\n","  data8 = (255*np.clip(all_preds, 0, 1)).astype(np.uint8)\n","  f = os.path.join(filename)\n","  imageio.mimwrite(f, data8, fps=20)\n","\n","  # Display video inline\n","  from IPython.display import HTML\n","  from base64 import b64encode\n","  mp4 = open(f, 'rb').read()\n","  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","\n","  N = len(outputs)\n","  if N == 1:\n","    return HTML(f'''\n","    <video width=256 controls autoplay loop>\n","          <source src=\"{data_url}\" type=\"video/mp4\">\n","    </video>\n","    ''')\n","  else:\n","    return HTML(f'''\n","    <video width=1000 controls autoplay loop>\n","          <source src=\"{data_url}\" type=\"video/mp4\">\n","    </video>\n","    <table width=\"1000\" cellspacing=\"0\" cellpadding=\"0\">\n","      <tr>{''.join(N*[f'<td width=\"{1000//len(outputs)}\"></td>'])}</tr>\n","      <tr>{''.join(N*['<td style=\"text-align:center\">{}</td>'])}</tr>\n","    </table>\n","    '''.format(*list(outputs.keys())))"]},{"cell_type":"markdown","metadata":{"id":"32nZKUI87j1U"},"source":["# Low Resolution Reconstruction"]},{"cell_type":"code","execution_count":133,"metadata":{"id":"uFU-rPCFn9mN"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/vk/btdnvgg54xl8ww32d4mbp6g00000gn/T/ipykernel_28210/1806870771.py:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n","  img = imageio.imread(image_url)[..., :3] / 255.\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["size = 32\n","train_data, test_data = get_image(size)"]},{"cell_type":"markdown","metadata":{"id":"csKDsiLaALNs"},"source":["Some suggested hyperparameter choices to help you start\n","- hidden layer count: 4\n","- hidden layer size: 256\n","- number of epochs: 1000\n","- learning reate: 1e-4\n"]},{"cell_type":"markdown","metadata":{"id":"63CMVVY9pCYy"},"source":["#### Low Resolution Reconstruction - SGD - None Mapping"]},{"cell_type":"code","execution_count":134,"metadata":{"id":"RVwNEfLSq_Ug"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb Cell 25\u001b[0m line \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# run NN experiment on input features\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m net, train_psnr, test_psnr, train_loss, predicted_images \u001b[39m=\u001b[39m NN_experiment(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     X_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train, X_test\u001b[39m=\u001b[39;49mX_test, y_test\u001b[39m=\u001b[39;49my_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     input_size\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], num_layers\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, hidden_size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, hidden_sizes\u001b[39m=\u001b[39;49m[\u001b[39m256\u001b[39;49m, \u001b[39m1024\u001b[39;49m, \u001b[39m1024\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m256\u001b[39;49m], output_size\u001b[39m=\u001b[39;49moutput_size, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m, opt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSGD\u001b[39;49m\u001b[39m'\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mbatch_size, weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, beta1\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# plot results of experiment\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plot_training_curves(train_loss, train_psnr, test_psnr)\n","\u001b[1;32m/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb Cell 25\u001b[0m line \u001b[0;36mNN_experiment\u001b[0;34m(X_train, y_train, X_test, y_test, input_size, num_layers, hidden_size, hidden_sizes, output_size, epochs, learning_rate, opt, batch_size, weight_decay, beta1)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m psnr_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m psnr(y_train_shuffled[i\u001b[39m*\u001b[39mBATCH_SIZE : (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mBATCH_SIZE], output)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Run the backward pass of the model to compute the loss, record the loss, and update the weights\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m loss_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mbackward(y_train_shuffled[i\u001b[39m*\u001b[39;49mBATCH_SIZE : (i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49mBATCH_SIZE])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# print('loss:', loss_)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ethan/UIUC/UIUC-CS444/assignment2/neural_network.ipynb#Y125sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m net\u001b[39m.\u001b[39mupdate(t\u001b[39m=\u001b[39mstep, lr\u001b[39m=\u001b[39mcur_lr, b1\u001b[39m=\u001b[39mbeta1, weight_decay\u001b[39m=\u001b[39mweight_decay)\n","File \u001b[0;32m~/UIUC/UIUC-CS444/assignment2/models/neural_net.py:167\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradients[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(c_z, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradients[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mact_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mT, c_z) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m--> 167\u001b[0m     back \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(c_z, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mW\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# get input features\n","B_dict = get_B_dict([])\n","mapping = 'none'\n","output_size = 3\n","X_train, y_train, X_test, y_test = get_input_features(B_dict, mapping)\n","batch_size = 128\n","\n","# run NN experiment on input features\n","net, train_psnr, test_psnr, train_loss, predicted_images = NN_experiment(\n","    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n","    input_size=X_train.shape[1], num_layers=6, hidden_size=None, hidden_sizes=[256, 1024, 1024, 512, 256], output_size=output_size, \n","    epochs=10, learning_rate=1e-2, opt='SGD', batch_size=batch_size, weight_decay=0, beta1=0.5\n",")\n","\n","# plot results of experiment\n","plot_training_curves(train_loss, train_psnr, test_psnr)\n","plot_reconstruction(net.forward(X_test), y_test)"]},{"cell_type":"markdown","metadata":{"id":"hvD5bj__qpjr"},"source":["#### Low Resolution Reconstruction - Optimizer of your Choice - Various Input Mapping Stategies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJn8Dp8IrBYI"},"outputs":[],"source":["def train_wrapper(mapping, size, lr, opt, weight_decay, beta1):\n","  # makes it easy to run all your mapping experiments in a for loop\n","  # this will similar to what you did previously in the last two sections\n","  \n","  output_size = 3\n","  X_train, y_train, X_test, y_test = get_input_features(B_dict, mapping)\n","  batch_size = 64\n","\n","  # run NN experiment on input features\n","  net, train_psnrs, test_psnrs, train_loss, predicted_images, test_loss = NN_experiment(\n","    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n","    input_size=X_train.shape[1], num_layers=7, hidden_size=None, hidden_sizes=[256, 256, 512, 512, 256, 256], output_size=output_size, \n","    epochs=8*250, learning_rate=lr, opt=opt, batch_size=batch_size, weight_decay=weight_decay, beta1=beta1\n","  )\n","\n","  # plot results of experiment\n","  plot_training_curves(train_loss, test_loss, train_psnr, test_psnr)\n","  plot_reconstruction(net.forward(X_test), y_test)\n","  plot_reconstruction_progress(predicted_images, y_test)\n","\n","  return {\n","    'net': net, \n","    'train_psnrs': train_psnrs, \n","    'test_psnrs': test_psnrs,\n","    'train_loss': train_loss,\n","    'pred_imgs': predicted_images\n","  }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-8E-xZFCLr6"},"outputs":[],"source":["outputs = {}\n","B_dict = get_B_dict([1.5, 2, 2.5, 5, 10]) \n","for k in (B_dict):\n","  print(\"training\", k)\n","  outputs[k] = train_wrapper(k, size, 1e-2, 'SGD', 1e-5, 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHshB7AvvwKC"},"outputs":[],"source":["# if you did everything correctly so far, this should output a nice figure you can use in your report\n","plot_feature_mapping_comparison(outputs, y_test.reshape(size,size,3))"]},{"cell_type":"markdown","metadata":{"id":"R3Xp9T9GxmS8"},"source":["# High Resolution Reconstruction"]},{"cell_type":"markdown","metadata":{"id":"PqiF7mqksn1M"},"source":["#### High Resolution Reconstruction - Optimizer of your Choice - Various Input Mapping Stategies"]},{"cell_type":"markdown","metadata":{"id":"wCcGOG_tstpz"},"source":["Repeat the previous experiment, but at the higher resolution. The reason why we have you first experiment with the lower resolution since it is faster to train and debug. Additionally, you will see how the mapping strategies perform better or worse at the two different input resolutions. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aoXjcQ1Wxski"},"outputs":[],"source":["size = 128\n","train_data, test_data = get_image(size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6xpU_WvskOh"},"outputs":[],"source":["outputs = {}\n","B_dict = get_B_dict([1, 2.5, 5, 10, 25, 50])\n","for k in (B_dict):\n","  print(\"training\", k)\n","  outputs[k] = train_wrapper(k, size, 1e-3, 'Adam', 1e-4, 0.9)"]},{"cell_type":"markdown","metadata":{"id":"BG2wNhrkvtFz"},"source":["#### High Resolution Reconstruction - Image of your Choice"]},{"cell_type":"markdown","metadata":{"id":"c8fm-X0wxY6f"},"source":["When choosing an image select one that you think will give you interesting results or a better insight into the performance of different feature mappings and explain why in your report template. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NLWTXXVvsZt"},"outputs":[],"source":["plot_feature_mapping_comparison(outputs, y_test.reshape(32,32,3))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","size = 256\n","# TODO pick an image and replace the url string\n","train_data, test_data = get_image(size, image_url=\"https://i.redd.it/z8oprysf4i4a1.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def NN_experiment(X_train, y_train, X_test, y_test, input_size, num_layers,\\\n","                  hidden_size, hidden_sizes, output_size, epochs,\\\n","                  learning_rate, opt, batch_size, weight_decay, beta1):\n","  \n","    # Initialize a new neural network model\n","    net = NeuralNetwork(input_size, hidden_sizes, output_size, num_layers, opt, batch_size=batch_size)\n","\n","    # Variables to store performance for each epoch\n","    train_loss = np.zeros(epochs)\n","    train_psnr = np.zeros(epochs)\n","    test_psnr = np.zeros(epochs)\n","    test_loss = np.zeros(epochs)\n","    predicted_images = np.zeros((epochs, y_test.shape[0], y_test.shape[1]))\n","\n","    # For each epoch...\n","\n","    BATCH_SIZE = batch_size\n","\n","    cur_lr = learning_rate\n","    step = 0\n","    for epoch in (range(epochs)):\n","        \n","        \n","        # Shuffle the dataset\n","        index = np.random.permutation(X_train.shape[0])\n","        X_train_shuffled = X_train[index]\n","        y_train_shuffled = y_train[index]\n","\n","        num_step = X_train.shape[0] // BATCH_SIZE \n","\n","        loss_ = 0.0\n","        psnr_ = 0.0\n","        for i in range(num_step):\n","            step += 1\n","            # Training\n","            # Run the forward pass of the model to get a prediction and record the psnr\n","            output = net.forward(X_train_shuffled[i*BATCH_SIZE : (i+1)*BATCH_SIZE])\n","            psnr_ += psnr(y_train_shuffled[i*BATCH_SIZE : (i+1)*BATCH_SIZE], output)\n","\n","            # Run the backward pass of the model to compute the loss, record the loss, and update the weights\n","            loss_ += net.backward(y_train_shuffled[i*BATCH_SIZE : (i+1)*BATCH_SIZE])\n","            # print('loss:', loss_)\n","            net.update(t=step, lr=cur_lr, b1=beta1, weight_decay=weight_decay)\n","\n","        train_loss[epoch] = loss_ / num_step\n","        train_psnr[epoch] = psnr_ / num_step\n","\n","        if (epoch+1)%50 == 0 and epoch > 1000 and opt == 'SGD':\n","            cur_lr *= 0.5\n","        elif (epoch+1)%200 == 0 and epoch > 600 and opt == 'Adam':\n","            cur_lr *= 0.8\n","\n","        \n","        # Testing\n","        # No need to run the backward pass here, just run the forward pass to compute and record the psnr\n","        predicted_images[epoch] = net.forward(X_test)\n","        test_psnr[epoch] = psnr(y_test, predicted_images[epoch])\n","        test_loss[epoch] = net.mse(y_test, predicted_images[epoch])\n","\n","        # print('testing psnr of epoch {}: {}'.format((epoch+1), psnr(y_test[i*BATCH_SIZE : (i+1)*BATCH_SIZE], output)))\n","        \n","    return net, train_psnr, test_psnr, train_loss, predicted_images, test_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_wrapper(mapping, size, lr, opt, weight_decay, beta1):\n","  # makes it easy to run all your mapping experiments in a for loop\n","  # this is similar to what you did previously in the last two sections\n","  \n","  output_size = 3\n","  X_train, y_train, X_test, y_test = get_input_features(B_dict, mapping)\n","  batch_size = 64\n","\n","  # run NN experiment on input features\n","  net, train_psnrs, test_psnrs, train_loss, predicted_images, test_loss = NN_experiment(\n","    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n","    input_size=X_train.shape[1], num_layers=5, hidden_size=None, hidden_sizes=[128, 256, 256, 128], output_size=output_size, \n","    epochs=8*150, learning_rate=lr, opt=opt, batch_size=batch_size, weight_decay=weight_decay, beta1=beta1\n","  )\n","\n","  # plot results of experiment\n","  plot_training_curves(train_loss, test_loss, train_psnr, test_psnr)\n","  plot_reconstruction(net.forward(X_test), y_test)\n","  plot_reconstruction_progress(predicted_images, y_test)\n","\n","  return {\n","    'net': net, \n","    'train_psnrs': train_psnrs, \n","    'test_psnrs': test_psnrs,\n","    'train_loss': train_loss,\n","    'pred_imgs': predicted_images\n","  }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["outputs = {}\n","B_dict = get_B_dict([1, 2.5, 5, 10, 25, 50])\n","for k in (B_dict):\n","  print(\"training\", k)\n","  outputs[k] = train_wrapper(k, size, 1e-3, 'Adam', 1e-4, 0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y4rA4SnRwH2u"},"outputs":[],"source":["plot_feature_mapping_comparison(outputs, y_test.reshape(32,32,3))"]},{"cell_type":"markdown","metadata":{"id":"jCE0yV-ytIu3"},"source":["# Reconstruction Process Video (Optional)\n","(For Fun!) Visualize the progress of training in a video "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkDM58n_tlMe"},"outputs":[],"source":["# requires installing this additional dependency\n","!pip install imageio-ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKA5lnTED2a5"},"outputs":[],"source":["# single video example\n","create_and_visualize_video({\"gauss\": {\"pred_imgs\": predicted_images}}, filename=\"training_high_res_gauss.mp4\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucNEYrqQvXsy"},"outputs":[],"source":["# multi video example\n","create_and_visualize_video(outputs, epochs=1000, size=32)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1BwVWCniWqdJ8uY3kEO45bDEKh4Sz33yr","timestamp":1676429175577},{"file_id":"1DAylBgQeNgfnhZZovWlZ-WTQbcBa1-OL","timestamp":1676420343251},{"file_id":"1JxUD-Tub-AyqVWKzTCQUfb2Y7VWNA7cn","timestamp":1675456427314},{"file_id":"https://github.com/tancik/fourier-feature-networks/blob/master/Demo.ipynb","timestamp":1675455979531}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.6.10 ('RL_MIMO')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"vscode":{"interpreter":{"hash":"5a76e50754b5e0a599f3c46cc139c51b64c27d3aa94b27906e8b81445e2e5a72"}}},"nbformat":4,"nbformat_minor":0}
